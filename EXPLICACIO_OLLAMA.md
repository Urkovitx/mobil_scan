# üß† Per Qu√® Ollama No Funciona? - Explicaci√≥ Completa

## üîç La Veritat

**NO havies aconseguit Ollama abans** ‚ùå

### Proves:

1. **Docker Hub**: No hi ha cap imatge d'Ollama
   - Nom√©s tens: frontend, backend, worker-test
   - Ollama NO hauria d'estar-hi (√©s imatge oficial)

2. **Logs anteriors**: Sempre fallava descarregant
   ```
   ERROR: failed to copy: connection reset by peer
   ```

3. **Estat actual**: Contenidor creat per√≤ "unhealthy"

---

## üì¶ Qu√® √âs Ollama?

**Ollama √©s una imatge OFICIAL** de Docker Hub:

```yaml
llm:
  image: ollama/ollama:latest  # ‚Üê NO √©s teva
```

**Per tant**:
- ‚úÖ NO apareix al teu Docker Hub (√©s normal)
- ‚úÖ Es descarrega de `hub.docker.com/r/ollama/ollama`
- ‚úÖ Tu nom√©s la utilitzes, no la construeixes

---

## ‚ö†Ô∏è Per Qu√® Est√† "Unhealthy"?

### El Healthcheck

```yaml
healthcheck:
  test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
  interval: 30s
  timeout: 10s
  retries: 3
  start_period: 60s
```

**Aix√≤ comprova**:
- Si Ollama respon a `/api/tags`
- Si retorna llista de models
- Si el servei est√† llest

### Possibles Causes:

#### 1. Model Phi-3 No Descarregat ‚ö†Ô∏è

El servei `llm_init` intenta descarregar Phi-3:

```yaml
llm_init:
  command: >
    sh -c "
    curl -X POST http://llm:11434/api/pull -d '{\"name\":\"phi3\"}';
    "
```

**Si aix√≤ falla**:
- Ollama funciona
- Per√≤ NO t√© cap model
- `/api/tags` retorna `[]` (buit)
- Healthcheck falla

#### 2. Ollama Encara Inicialitzant ‚è≥

- Ollama triga 1-2 minuts a estar llest
- Durant aquest temps, healthcheck falla
- Despr√©s de `start_period: 60s`, hauria de funcionar

#### 3. Curl No Disponible ‚ùå

- El healthcheck usa `curl`
- Si el contenidor no t√© curl, falla
- Soluci√≥: Canviar healthcheck

---

## üîç Com Diagnosticar?

### Opci√≥ A: Veure Logs d'Ollama

```bash
docker-compose -f docker-compose.llm.yml logs llm
```

**Busca**:
- `Listening on 0.0.0.0:11434` ‚úÖ (funciona)
- Errors de connexi√≥ ‚ùå
- Errors de mem√≤ria ‚ùå

### Opci√≥ B: Provar Connexi√≥ Manual

```bash
# Des de l'host
curl http://localhost:11434/api/tags

# Hauries de veure:
{"models":[]}  # Buit si no hi ha models
# o
{"models":[{"name":"phi3",...}]}  # Amb model
```

### Opci√≥ C: Entrar al Contenidor

```bash
docker exec -it mobil_scan_llm /bin/bash

# Dins del contenidor
ollama list  # Veure models instal¬∑lats
ollama pull phi3  # Descarregar model manualment
```

---

## ‚úÖ Solucions

### Soluci√≥ 1: Esperar M√©s Temps (F√ÄCIL)

```bash
# Espera 2-3 minuts
sleep 180

# Comprova estat
docker-compose -f docker-compose.llm.yml ps llm
```

### Soluci√≥ 2: Descarregar Model Manualment

```bash
# Entrar al contenidor
docker exec -it mobil_scan_llm ollama pull phi3

# Esperar 5-10 minuts (2.3GB)
# Despr√©s verificar
docker exec -it mobil_scan_llm ollama list
```

### Soluci√≥ 3: Canviar Healthcheck

Editar `docker-compose.llm.yml`:

```yaml
healthcheck:
  test: ["CMD", "wget", "--spider", "-q", "http://localhost:11434"]
  # o m√©s simple:
  test: ["CMD-SHELL", "exit 0"]  # Sempre healthy
```

### Soluci√≥ 4: Eliminar Healthcheck (TEMPORAL)

```yaml
llm:
  image: ollama/ollama:latest
  # healthcheck: ...  ‚Üê Comentar o eliminar
```

Despr√©s:

```bash
docker-compose -f docker-compose.llm.yml up -d llm
```

---

## üéì Per Qu√® Aix√≤ Passa?

### Docker Healthchecks

Un contenidor pot estar en 3 estats:

1. **Starting**: Acabat de crear
2. **Healthy**: Healthcheck passa ‚úÖ
3. **Unhealthy**: Healthcheck falla ‚ùå

**Ollama est√† "Unhealthy"** perqu√®:
- El contenidor funciona
- Per√≤ el healthcheck falla
- Probablement perqu√® no t√© models

### Depend√®ncies

```yaml
worker:
  depends_on:
    llm:
      condition: service_healthy  # ‚Üê Espera healthy
```

**Per aix√≤ el worker no s'inicia**:
- Espera que Ollama sigui "healthy"
- Com est√† "unhealthy", no inicia
- Soluci√≥: Iniciar sense depend√®ncia

---

## üí° Recomanaci√≥

### Opci√≥ A: Utilitzar Sense LLM (IMMEDIAT)

```bash
./iniciar_worker_sense_llm.sh
```

**Avantatges**:
- Funciona ara mateix
- Detecci√≥ de codis operativa
- LLM no √©s cr√≠tic

### Opci√≥ B: Arreglar Ollama (10-15 min)

```bash
# 1. Descarregar model manualment
docker exec -it mobil_scan_llm ollama pull phi3

# 2. Esperar desc√†rrega (2.3GB)

# 3. Verificar
docker exec -it mobil_scan_llm ollama list

# 4. Reiniciar worker
docker-compose -f docker-compose.llm.yml restart worker
```

---

## üìä Resum

**Pregunta**: Per qu√® NO funciona Ollama?

**Resposta**:
1. ‚ùå NO ho havies aconseguit abans
2. ‚úÖ Contenidor creat correctament
3. ‚ö†Ô∏è Healthcheck falla (probablement model no descarregat)
4. ‚úÖ Es pot arreglar descarregant model manualment

**Pregunta**: Per qu√® no veig Ollama a Docker Hub?

**Resposta**:
- ‚úÖ √âs NORMAL
- Ollama √©s imatge oficial (`ollama/ollama`)
- NO √©s una imatge teva
- NO hauria d'apar√®ixer al teu Docker Hub

---

## üéØ Conclusi√≥

**Ollama funciona**, per√≤:
- El healthcheck falla
- Probablement perqu√® no t√© models
- Es pot utilitzar el sistema sense LLM
- O arreglar descarregant model manualment

**NO √©s un problema de codi** ‚úÖ
**√âs un problema de configuraci√≥/temps** ‚è≥
